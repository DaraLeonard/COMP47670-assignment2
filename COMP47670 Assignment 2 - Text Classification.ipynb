{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# COMP47670 Assignment 2 - Text Classification\n",
    "\n",
    "#### Student Name: Dara Leonard\n",
    "#### Student ID: 19202478"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1: Scrape all reviews for each category and store them as three separate datasets\n",
    "For Task 1 I have chosen the Automotive, Cafes, and Fashion categories as my data sources.\n",
    "\n",
    "The following four methods extract the review data from the data source (Yalp) and parses it out into three pandas\n",
    "data frames, one for each of the chosen categories. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "data_source = 'http://mlg.ucd.ie/modules/yalp/'\n",
    "business_categories = ['automotive_list.html', 'cafes_list.html', 'fashion_list.html']\n",
    "\n",
    "def extract_category_data(url):\n",
    "    response = requests.get(url)\n",
    "    data = response.text\n",
    "    return BeautifulSoup(data,'html.parser')\n",
    "\n",
    "\n",
    "def categorise_rating(review_stars):\n",
    "    return 'positive' if int(review_stars.get('alt').split('-')[0]) >= 4 else 'negative'\n",
    "\n",
    "\n",
    "def extract_reviews(url):\n",
    "    soup = extract_category_data(url)\n",
    "    reviews_block = soup.findAll('div', { 'class' : 'review' })\n",
    "    review_list =[]\n",
    "    review_info_columns = ['comment', 'rating']\n",
    "    review_df = pd.DataFrame(columns=review_info_columns)\n",
    "\n",
    "    for i, reviews in enumerate(reviews_block):\n",
    "        review = {}\n",
    "        review_stars = reviews.find('img')\n",
    "        review['comments'] = reviews.find('p', { 'class' : 'review-text' }).get_text()\n",
    "        review['rating'] = categorise_rating(review_stars)\n",
    "        review_list.append(review)        \n",
    "        \n",
    "        review_tmp = dict({\n",
    "            'comment': reviews.find('p', { 'class' : 'review-text' }).get_text(),\n",
    "            'rating' : categorise_rating(review_stars)\n",
    "        })\n",
    "        review_df.loc[i] = review_tmp\n",
    "\n",
    "    return review_list, review_df\n",
    "\n",
    "\n",
    "def extract_data(url):\n",
    "    soup = extract_category_data(url)\n",
    "    links = soup.find_all('a')\n",
    "    review_list =[]\n",
    "    for link in links:\n",
    "        url = data_source + link.get('href')\n",
    "        review, review_df = extract_reviews(url)\n",
    "        review_list.append(review_df)\n",
    "    return pd.concat(review_list)\n",
    "\n",
    "\n",
    "automotive_url = data_source + business_categories[0]\n",
    "cafe_url = data_source + business_categories[1]\n",
    "fashion_url = data_source + business_categories[2]\n",
    "\n",
    "automotive_reviews_df = extract_data(automotive_url)\n",
    "cafe_reviews_df = extract_data(cafe_url)\n",
    "fashion_reviews_df = extract_data(fashion_url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following chunk of logic is dumping the data out to a json file. This will allow the program to be ran in a shorter\n",
    "amount of time by just reading the already collected data and performing the analysis. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "automotive_reviews_df.to_json('automotive.json', orient='records')\n",
    "cafe_reviews_df.to_json('cafe.json', orient='records')\n",
    "fashion_reviews_df.to_json('fashion.json', orient='records')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Re-read the data from the data already collected from Yalp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "consolidated_automotive_reviews_df = pd.read_json('automotive.json', orient='records')\n",
    "consolidated_cafe_reviews_df = pd.read_json('cafe.json', orient='records')\n",
    "consolidated_fashion_reviews_df = pd.read_json('fashion.json', orient='records')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display a snapshot of each of the data frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             comment    rating\n0  The man that was working tonight (8-12-17) was...  negative\n1  Chris is a very rude person. Gave me an attitu...  negative\n2  One of my favorite gas station to stop at. The...  positive\n3  Oh thank Heaven for Seven Eleven! I don't know...  negative\n4  Five stars because of the guy who works weekda...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The man that was working tonight (8-12-17) was...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Chris is a very rude person. Gave me an attitu...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>One of my favorite gas station to stop at. The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Oh thank Heaven for Seven Eleven! I don't know...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Five stars because of the guy who works weekda...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 48
    }
   ],
   "source": [
    "consolidated_automotive_reviews_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             comment    rating\n0  Pros: Lots of items you would not expect from ...  positive\n1  Best egg-tarts in town! There's really not muc...  positive\n2  I've been to ABC Bakery a few times since I re...  negative\n3  FYI, Closed Monday's New ownership for about 1...  negative\n4  The inside may not look like much but they mak...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pros: Lots of items you would not expect from ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Best egg-tarts in town! There's really not muc...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I've been to ABC Bakery a few times since I re...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FYI, Closed Monday's New ownership for about 1...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The inside may not look like much but they mak...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 49
    }
   ],
   "source": [
    "consolidated_cafe_reviews_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             comment    rating\n0  Looking for the best tactical supplies? Look n...  positive\n1  Stood in line like an idiot for 5 minutes to p...  negative\n2  Another great store with quality Equipment. Th...  positive\n3  The Problem with this store is not that they h...  positive\n4  Great place! We went in at almost closing time...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Looking for the best tactical supplies? Look n...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Stood in line like an idiot for 5 minutes to p...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Another great store with quality Equipment. Th...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Problem with this store is not that they h...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Great place! We went in at almost closing time...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 50
    }
   ],
   "source": [
    "consolidated_fashion_reviews_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check to see the dimensions of each of the data frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 2)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 51
    }
   ],
   "source": [
    "consolidated_automotive_reviews_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 2)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 52
    }
   ],
   "source": [
    "consolidated_cafe_reviews_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 2)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 53
    }
   ],
   "source": [
    "consolidated_fashion_reviews_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do a check to see if there's any missing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "comment    0\nrating     0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 54
    }
   ],
   "source": [
    "consolidated_automotive_reviews_df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "comment    0\nrating     0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 55
    }
   ],
   "source": [
    "consolidated_cafe_reviews_df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "comment    0\nrating     0\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 56
    }
   ],
   "source": [
    "consolidated_fashion_reviews_df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do a check on the nature of the reviews to see the ratio of positive to negative"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "rating\nnegative     788\npositive    1212\nName: rating, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 57
    }
   ],
   "source": [
    "consolidated_automotive_reviews_df.groupby('rating')['rating'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "rating\nnegative     538\npositive    1462\nName: rating, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 58
    }
   ],
   "source": [
    "consolidated_cafe_reviews_df.groupby('rating')['rating'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "rating\nnegative     795\npositive    1205\nName: rating, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 59
    }
   ],
   "source": [
    "consolidated_fashion_reviews_df.groupby('rating')['rating'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2: For each of the chosen categories; apply any necessary pre-processing, build a classification model & test said classification model\n",
    "\n",
    "\n",
    "### 2.1 Normalise Data \n",
    "The following five methods are tasked with pre-processing the data:\n",
    "1. remove_stop_words - Remove the stopwords in the review like 'is', 'an', etc. They do not contribute to the efficiency of the classifier\n",
    "2. remove_numeric_special - Remove any special and numeric characters\n",
    "3. converted_strings_to_lowercase - convert all characters in every review to lower case\n",
    "4. lemmatize - Sort words in each review so as to group together inflected or variant forms of the same word.\n",
    "5. preprocess_data_frame - Calls each of the methods specified above"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def remove_stop_words(data_frame):\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "    data_frame['comment']=data_frame['comment'].apply(lambda i:  pattern.sub('', i) if len(i) > 0 else i ) \n",
    "    \n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def remove_numeric_special(data_frame):\n",
    "    data_frame['comment']=data_frame['comment'].apply(lambda i:  re.sub('[^A-Za-z]+', ' ', i)  if len(i) > 0 else i ) \n",
    "    return data_frame \n",
    "\n",
    "\n",
    "def converted_strings_to_lowercase(data_frame):\n",
    "    data_frame['comment']=data_frame['comment'].str.lower()\n",
    "    return data_frame \n",
    "\n",
    "def lemmatize(data_frame):\n",
    "    lemmatizer = WordNetLemmatizer()       \n",
    "    data_frame['comment'] = data_frame['comment'].apply(lambda j: ''.join([lemmatizer.lemmatize(i) for i in j]))\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def preprocess_data_frame(data_frame):\n",
    "    preprocessed_data_frame = remove_stop_words(data_frame)\n",
    "    preprocessed_data_frame = remove_numeric_special(preprocessed_data_frame)\n",
    "    preprocessed_data_frame = converted_strings_to_lowercase(preprocessed_data_frame)\n",
    "    return lemmatize(preprocessed_data_frame)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Merging the dataset to build the classifier\n",
    "\n",
    "Merging the three data sets to form a unified dataset before normailising the data using the functions written in Task 2.1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "combined_data_frame = consolidated_automotive_reviews_df.append(consolidated_cafe_reviews_df).append(consolidated_fashion_reviews_df)\n",
    "\n",
    "cleaned_combined_data = preprocess_data_frame(combined_data_frame)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get a description of the data to see counts, unique count etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  comment    rating\ncount                                                6000      6000\nunique                                               6000         2\ntop     must say thankful able opportunity work really...  positive\nfreq                                                    1      3879",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6000</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>6000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>must say thankful able opportunity work really...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>3879</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 62
    }
   ],
   "source": [
    "cleaned_combined_data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preview the new data set to see all words have been normalised"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             comment    rating\n0  the man working tonight rude a real jerk i nee...  negative\n1  chris rude person gave attitude change some pe...  negative\n2  one favorite gas station stop the store always...  positive\n3  oh thank heaven seven eleven i know i thank se...  negative\n4  five stars guy works weekday mornings around a...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the man working tonight rude a real jerk i nee...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>chris rude person gave attitude change some pe...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>one favorite gas station stop the store always...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>oh thank heaven seven eleven i know i thank se...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>five stars guy works weekday mornings around a...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 63
    }
   ],
   "source": [
    "cleaned_combined_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Choosing the classifier\n",
    "Let's run some quick experiments to see which of the three available classifiers are the most accurate on one of the data sets.\n",
    "I am using the automotive category only in these experiments\n",
    "\n",
    "Before building the models, I'm defining a function to display the performance metrics of each model based on their confusion matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model_performance(confusion_matrix):\n",
    "    total = sum(sum(confusion_matrix))\n",
    "\n",
    "    true_negative, false_negative = confusion_matrix[0][0], confusion_matrix[1][0]\n",
    "    true_positive, false_positive = confusion_matrix[1][1], confusion_matrix[0][1]\n",
    "    \n",
    "    print('Confusion Matrix: \\\n",
    "      \\n \\t \\t| Positive  | Negative \\\n",
    "      \\n Positive \\t| {true_negative} \\t| {false_positive} \\\n",
    "      \\n Negative \\t| {false_negative} \\t| {true_positive}')\n",
    "\n",
    "    accuracy = (true_negative + true_positive)/ total\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "    error_rate = 1 - accuracy\n",
    "    print('Error rate: {:.2f}%'.format(error_rate*100))\n",
    "\n",
    "    sensitivity = true_positive/(true_positive + false_negative)\n",
    "    print('Sensitivity: {:.2f}%'.format(sensitivity*100))\n",
    "\n",
    "    false_positive_rate = false_positive/(true_negative + false_positive)\n",
    "    print('False positive rate: {:.2f}%'.format(false_positive_rate*100))\n",
    "    \n",
    "    specificity = true_negative/(true_negative + false_positive)\n",
    "    print('Specificity: {:.2f}%'.format(specificity*100))\n",
    "    \n",
    "    precision = true_positive/(false_positive + true_positive)\n",
    "    print('Precision rate: {:.2f}%'.format(precision*100))\n",
    "    \n",
    "    prevalence = (false_negative + true_positive)/total\n",
    "    print('Prevalence rate: {:.2f}%'.format(prevalence*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.1 Logistic Regression\n",
    "\n",
    "Create a TfidfVectorizer to create a numeric representation of the dataset and set the target value for the classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "(6000, 18910)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 65
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "corpus = cleaned_combined_data['comment']\n",
    "X_merged = tfidf_vectorizer.fit_transform(corpus)\n",
    "y_merged = cleaned_combined_data['rating']\n",
    "X_merged.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now I will split the data to use the automotive category data to build the experimental models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_automotiveReviewSize = consolidated_automotive_reviews_df.shape[0]\n",
    "X_automotive = X_merged[:X_automotiveReviewSize]\n",
    "target_automotive = y_merged[:X_automotiveReviewSize]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Identify the dimensions of the separated data set to ensure they match what they were previously"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 18910)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 67
    }
   ],
   "source": [
    "X_automotive.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Partition the data to use for the classifier. I chose a standard split of 70% training and 30% test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "automotive_data_train, automotive_data_test, automotive_target_train, automotive_target_test = train_test_split(X_automotive, target_automotive, test_size=0.3, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display the shapes of the training and testing data sets "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Automotive training data set size: 1400\nAutomotive test data set size: 600 \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Automotive training data set size: %d' % automotive_data_train.shape[0])\n",
    "print('Automotive test data set size: %d ' % automotive_data_test.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train each of the models using each of the training data sets and then use the test data to test said models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "automotive_model_log_reg = linear_model.LogisticRegression(solver='liblinear')\n",
    "automotive_model_log_reg.fit(automotive_data_train, automotive_target_train)\n",
    "\n",
    "predicted_automotive_log_reg = automotive_model_log_reg.predict(automotive_data_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.2 Naive Bayes\n",
    "\n",
    "Build a Naive Bayes model with the same training data as used in the logistic regression classifier and then use the \n",
    "test data to test said model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "automotive_model_naive_bayes = MultinomialNB().fit(automotive_data_train, automotive_target_train)\n",
    "\n",
    "predicted_automotive_naive_bayes = automotive_model_naive_bayes.predict(automotive_data_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.3 Random Forests\n",
    "Build a Random Forests model with the same training data as used in the logistic regression and naive bayes classifiers above\n",
    "\n",
    "To get the best results from the Random Forests model some parameter tuning is required. To do this GridSearchCV can be used\n",
    "to tune the hyper parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.0min finished\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=50, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 72
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "random_forest_param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [30, 40, 50],\n",
    "    'n_estimators': [100, 200, 300, 500]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = random_forest, param_grid = random_forest_param_grid, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(automotive_data_train, automotive_target_train) \n",
    "\n",
    "automotive_model_score_random_forest = grid_search.best_estimator_\n",
    "automotive_model_score_random_forest.fit(automotive_data_test, automotive_target_test) \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_automotive_random_forest = automotive_model_score_random_forest.predict(automotive_data_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After building each of the classifiers with the automotive data set, the metrics for each model can now be gathered\n",
    "\n",
    "#### Logistic Regression Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix:       \n \t \t| Positive  | Negative       \n Positive \t| {true_negative} \t| {false_positive}       \n Negative \t| {false_negative} \t| {true_positive}\nAccuracy: 90.67%\nError rate: 9.33%\nSensitivity: 83.93%\nFalse positive rate: 5.32%\nSpecificity: 94.68%\nPrecision rate: 90.38%\nPrevalence rate: 37.33%\n              precision    recall  f1-score   support\n\n    negative       0.90      0.84      0.87       224\n    positive       0.91      0.95      0.93       376\n\n    accuracy                           0.91       600\n   macro avg       0.91      0.89      0.90       600\nweighted avg       0.91      0.91      0.91       600\n\n",
      "Mean cross-validation accuracy of the logistic regression model: 0.89\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "evaluate_model_performance(confusion_matrix(automotive_target_test, predicted_automotive_log_reg, labels=['positive','negative']))\n",
    "print(classification_report(automotive_target_test, predicted_automotive_log_reg, target_names=['negative','positive']))\n",
    "automotive_model_cross_validation_score_log_reg =  cross_val_score(automotive_model_log_reg, X_automotive, target_automotive, cv=10, scoring='accuracy')\n",
    "print('Mean cross-validation accuracy of the logistic regression model: %.2f' % automotive_model_cross_validation_score_log_reg.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Naive Bayes Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix:       \n \t \t| Positive  | Negative       \n Positive \t| {true_negative} \t| {false_positive}       \n Negative \t| {false_negative} \t| {true_positive}\nAccuracy: 78.67%\nError rate: 21.33%\nSensitivity: 43.30%\nFalse positive rate: 0.27%\nSpecificity: 99.73%\nPrecision rate: 98.98%\nPrevalence rate: 37.33%\n              precision    recall  f1-score   support\n\n    negative       0.99      0.43      0.60       224\n    positive       0.75      1.00      0.85       376\n\n    accuracy                           0.79       600\n   macro avg       0.87      0.72      0.73       600\nweighted avg       0.84      0.79      0.76       600\n\n",
      "Mean cross-validation accuracy of the Naive Bayes model: 0.77\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "evaluate_model_performance(confusion_matrix(automotive_target_test, predicted_automotive_naive_bayes, labels=['positive','negative']))\n",
    "print(classification_report(automotive_target_test, predicted_automotive_naive_bayes, target_names=['negative','positive']))\n",
    "automotive_model_cross_validation_score_naive_bayes =  cross_val_score(automotive_model_naive_bayes, X_automotive, target_automotive, cv=10, scoring='accuracy')\n",
    "print('Mean cross-validation accuracy of the Naive Bayes model: %.2f' % automotive_model_cross_validation_score_naive_bayes.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix:       \n \t \t| Positive  | Negative       \n Positive \t| {true_negative} \t| {false_positive}       \n Negative \t| {false_negative} \t| {true_positive}\nAccuracy: 100.00%\nError rate: 0.00%\nSensitivity: 100.00%\nFalse positive rate: 0.00%\nSpecificity: 100.00%\nPrecision rate: 100.00%\nPrevalence rate: 37.33%\n              precision    recall  f1-score   support\n\n    negative       1.00      1.00      1.00       224\n    positive       1.00      1.00      1.00       376\n\n    accuracy                           1.00       600\n   macro avg       1.00      1.00      1.00       600\nweighted avg       1.00      1.00      1.00       600\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "evaluate_model_performance(confusion_matrix(automotive_target_test, predicted_automotive_random_forest, labels=['positive','negative']))\n",
    "print(classification_report(automotive_target_test, predicted_automotive_random_forest, target_names=['negative','positive']))\n",
    "automotive_model_cross_validation_score_random_forest =  cross_val_score(automotive_model_score_random_forest, X_automotive, target_automotive, cv=10, scoring='accuracy')\n",
    "print('Mean cross-validation accuracy of the Random Forests model: %.2f' % automotive_model_cross_validation_score_random_forest.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the accuracy of each of the models can be plotted\n",
    "\n",
    "I have chosen 10-fold cross validation as the classification evaluation metric as it trains and tests on all data available."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_results = [automotive_model_cross_validation_score_log_reg.mean(), automotive_model_cross_validation_score_naive_bayes.mean(), automotive_model_cross_validation_score_random_forest.mean()]\n",
    "index = np.arange(len(accuracy_results))\n",
    "plt.figure(figsize=(8,6))\n",
    "bar_list = plt.bar(index, accuracy_results, width=0.5)\n",
    "for bar in bar_list:\n",
    "    yval = round(bar.get_height(), 3)\n",
    "    plt.text(bar.get_x()+0.15, yval + .005, yval)\n",
    "\n",
    "bar_list[0].set_color('g')\n",
    "bar_list[1].set_color('g')\n",
    "bar_list[2].set_color('g')\n",
    "\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(index, ['Logistic Regression', 'Naive Bayes', 'Random Forests'])\n",
    "plt.title('Classifier Accuracy')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the results above, the logistic regression model has a slightly better accuracy than the one built using Random Forests.\n",
    "Random Forests did have have a better accuracy according to its confusion matrix, but I felt like 10-fold cross validation was\n",
    "a better metric to go by. It was also a lot more computationally expensive due to the parameter tuning. \n",
    "\n",
    "##### 2.3 Building each of the logistic regression models using each of the chosen categories\n",
    "\n",
    "First the cafe and fashion data needs to be extracted from the merged data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_cafeReviewSize = consolidated_cafe_reviews_df.shape[0]\n",
    "X_fashionReviewSize = consolidated_fashion_reviews_df.shape[0]\n",
    "\n",
    "X_cafe = X_merged[X_automotiveReviewSize:X_automotiveReviewSize + X_cafeReviewSize]\n",
    "target_cafe = y_merged[X_automotiveReviewSize:X_automotiveReviewSize + X_cafeReviewSize]\n",
    "\n",
    "X_fashion = X_merged[X_automotiveReviewSize + X_cafeReviewSize:]\n",
    "target_fashion = y_merged[X_automotiveReviewSize + X_cafeReviewSize:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then a quick inspection is done of each of these data sets to ensure they are the correct size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_cafe.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_fashion.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then the model for each of the other two categories can be built"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cafe_data_train, cafe_data_test, cafe_target_train, cafe_target_test = train_test_split(X_cafe, target_cafe, test_size=0.3, shuffle=True)\n",
    "fashion_data_train, fashion_data_test, fashion_target_train, fashion_target_test = train_test_split(X_fashion, target_fashion, test_size=0.3, shuffle=True)\n",
    "\n",
    "cafe_model_log_reg = linear_model.LogisticRegression(solver='liblinear')\n",
    "cafe_model_log_reg.fit(cafe_data_train, cafe_target_train)\n",
    "\n",
    "fashion_model_log_reg = linear_model.LogisticRegression(solver='liblinear')\n",
    "fashion_model_log_reg.fit(fashion_data_train, fashion_target_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "automotive_model_cross_validation_score_log_reg =  cross_val_score(automotive_model_log_reg, X_automotive, target_automotive, cv=10, scoring='accuracy')\n",
    "print('Mean cross-validation accuracy of the logistic regression model - automotive: %.2f' % automotive_model_cross_validation_score_log_reg.mean())\n",
    "\n",
    "cafe_model_cross_validation_score_log_reg =  cross_val_score(cafe_model_log_reg, X_cafe, target_cafe, cv=10, scoring='accuracy')\n",
    "print('Mean cross-validation accuracy of the logistic regression model - cafe: %.2f' % cafe_model_cross_validation_score_log_reg.mean())\n",
    "\n",
    "fashion_model_cross_validation_score_log_reg =  cross_val_score(fashion_model_log_reg, X_fashion, target_fashion, cv=10, scoring='accuracy')\n",
    "print('Mean cross-validation accuracy of the logistic regression model - fashion: %.2f' % fashion_model_cross_validation_score_log_reg.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the results above, a graph of the accuracy of each of the models can be produced"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_reg_accuracy_results = [automotive_model_cross_validation_score_log_reg.mean(), cafe_model_cross_validation_score_log_reg.mean(), fashion_model_cross_validation_score_log_reg.mean()]\n",
    "log_reg_index = np.arange(len(log_reg_accuracy_results))\n",
    "plt.figure(figsize=(8,6))\n",
    "bar_list_log_reg_accuracy_results = plt.bar(index, log_reg_accuracy_results, width=0.5)\n",
    "for bar in bar_list_log_reg_accuracy_results:\n",
    "    y_val = round(bar.get_height(), 3)\n",
    "    plt.text(bar.get_x()+0.15, y_val + .005, y_val)\n",
    "\n",
    "bar_list_log_reg_accuracy_results[0].set_color('g')\n",
    "bar_list_log_reg_accuracy_results[1].set_color('g')\n",
    "bar_list_log_reg_accuracy_results[2].set_color('g')\n",
    "\n",
    "plt.xlabel('Data Set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(index, ['Automotive', 'Cafe', 'Fashion'])\n",
    "plt.title('Logistic Regression Model Accuracy on Each Data Source')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3: Evaluate the performance of each classification model when applied to data from the other two selected categories.\n",
    "\n",
    "Since now the three models are created - automotive_model_log_reg, cafe_model_log_reg, fashion_model_log_reg, Task 3 can be started\n",
    "\n",
    "10-fold cross validation was again chosen to maintain consistency with the methods used above\n",
    "### 2.1 Training on automotive data and evaluating on cafe and fashion data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "automotive_model_all_data = linear_model.LogisticRegression(solver='liblinear')\n",
    "automotive_model_all_data.fit(X_automotive, target_automotive)\n",
    "\n",
    "trained_on_automotive_tested_on_cafe_cv_score =  cross_val_score(automotive_model_all_data, X_cafe, target_cafe, cv=10, scoring='accuracy')\n",
    "print('Accuracy of model trained on automotive data and tested on cafe data: %.2f' % trained_on_automotive_tested_on_cafe_cv_score.mean())\n",
    "trained_on_automotive_tested_on_fashion_cv_score =  cross_val_score(automotive_model_all_data, X_fashion, target_fashion, cv=10, scoring='accuracy')\n",
    "print('Accuracy of model trained on automotive data and tested on fashion data: %.2f' % trained_on_automotive_tested_on_fashion_cv_score.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Training on cafe data and evaluating on automotive and fashion data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cafe_model_all_data = linear_model.LogisticRegression(solver='liblinear')\n",
    "cafe_model_all_data.fit(X_cafe, target_cafe)\n",
    "\n",
    "trained_on_cafe_tested_on_automotive_cv_score =  cross_val_score(cafe_model_all_data, X_automotive, target_automotive, cv=10, scoring='accuracy')\n",
    "print('Accuracy of model trained on cafe data and tested on automotive data: %.2f' % trained_on_cafe_tested_on_automotive_cv_score.mean())\n",
    "trained_on_cafe_tested_on_fashion_cv_score =  cross_val_score(cafe_model_all_data, X_fashion, target_fashion, cv=10, scoring='accuracy')\n",
    "print('Accuracy of model trained on cafe data and tested on fashion data: %.2f' % trained_on_cafe_tested_on_fashion_cv_score.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Training on fashion data and evaluating on automotive and cafe data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fashion_model_all_data = linear_model.LogisticRegression(solver='liblinear')\n",
    "fashion_model_all_data.fit(X_fashion, target_fashion)\n",
    "\n",
    "trained_on_fashion_tested_on_automotive_cv_score =  cross_val_score(fashion_model_all_data, X_automotive, target_automotive, cv=10, scoring='accuracy')\n",
    "print('Accuracy of model trained on fashion data and tested on automotive data: %.2f' % trained_on_fashion_tested_on_automotive_cv_score.mean())\n",
    "trained_on_fashion_tested_on_cafe_cv_score =  cross_val_score(fashion_model_all_data, X_cafe, target_cafe, cv=10, scoring='accuracy')\n",
    "print('Accuracy of model trained on fashion data and tested on cafe data: %.2f' % trained_on_fashion_tested_on_cafe_cv_score.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Conclusion\n",
    "The accuracy values of the models are different but comparable when used on a category other than what it was trained on. This is because, each \n",
    "category would presumably contain words that correspond only to their category alone. \n",
    "\n",
    "Each of the models trained on another category would not have identified these new keywords as an important factor in the classification of each\n",
    "review as it still gives priority to the keywords it found in the category it was trained on.\n",
    "\n",
    "It should be noted that the models have shown a comparable accuracy with the data values for a different category as general words contained in a\n",
    "positive review are always similar no matter what category we choose, likewise with negative reviews."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}